ğŸ‘‰ Type: Static Array

1. Insert at End

âœ¨ Flashcard
"Place at arr[length] â†’ increment length."

âš¡ Full Approach
Steps:

Check if thereâ€™s capacity (length < capacity).
Insert the new value at arr[length].
Return updated length (length + 1).

â±ï¸ Complexity

Time: O(1) â†’ Direct insertion.
Space: O(1) â†’ No extra memory.

2. Remove from End

âœ¨ Flashcard
"Clear arr[length-1] â†’ decrement length."

âš¡ Full Approach
Steps:

Check if the array is non-empty (length > 0).
Reset last element (arr[length-1] = 0).
Return updated length (length - 1).

â±ï¸ Complexity

Time: O(1) â†’ Direct removal.
Space: O(1) â†’ No extra memory.

3. Insert in Middle

âœ¨ Flashcard
"Shift right â†’ place value â†’ increment length."

âš¡ Full Approach
Steps:

Start from the last real element (length - 1) down to i.
Shift each element one step to the right (arr[index + 1] = arr[index]).
Insert the value at position i.
Return updated length (length + 1).

â±ï¸ Complexity

Time: O(n) â†’ Shifting elements.
Space: O(1) â†’ No extra memory.

4. Remove from Middle

âœ¨ Flashcard
"Shift left â†’ clear last slot â†’ decrement length."

âš¡ Full Approach
Steps:

Start from i+1 to the end (length - 1).
Shift elements one step to the left (arr[index-1] = arr[index]).
Reset last slot (arr[length-1] = 0).
Return updated length (length - 1).

â±ï¸ Complexity

Time: O(n) â†’ Shifting elements.
Space: O(1) â†’ No extra memory.

5. Print Array

âœ¨ Flashcard
"Loop from 0 â†’ capacity â†’ print each value."

âš¡ Full Approach
Steps:

Loop through 0 to capacity-1.
Print each arr[i].

â±ï¸ Complexity

Time: O(n) â†’ Iterate through array.

Space: O(1) â†’ No extra memory.

ğŸ‘‰ Type: Stack (Dynamic Array)

1. Push (Insert at Top)

âœ¨ Flashcard
"Append to list â†’ top grows upward."

âš¡ Full Approach
Steps:

Call append(n) to add element at the end of the list.
The new element becomes the top of the stack.

â±ï¸ Complexity

Time: O(1) â†’ Direct append.
Space: O(1) â†’ No extra memory (except element storage).

2. Pop (Remove from Top)

âœ¨ Flashcard
"Pop last â†’ return top element."

âš¡ Full Approach
Steps:

Call pop() to remove the last element.
Return the removed element (the previous top).

â±ï¸ Complexity

Time: O(1) â†’ Direct pop from end.
Space: O(1) â†’ No extra memory.

ğŸ‘‰ Type: Singly Linked List

1. Insert Node at End

âœ¨ Flashcard
"Create new_node â†’ link tail.next â†’ move tail."

âš¡ Full Approach
Steps:

Create a new node (new_node = ListNode(val)).
Link the current tail node to the new node (self.tail.next = new_node).
Move self.tail to point to the new node (self.tail = new_node).

â±ï¸ Complexity

Time: O(1) â†’ Direct tail reference.
Space: O(1) â†’ No extra memory.

2. Remove Node at Given Index

âœ¨ Flashcard
"Traverse to node before target â†’ skip target â†’ update tail if last node removed."

âš¡ Full Approach
Steps:

Start from the dummy head node (curr = self.head).
Use a for loop to move curr forward index times.
If curr.next is None, index is out of range â†’ exit function.

Once at the node before the target, update link:
curr.next = curr.next.next

If we removed the last node, update:
self.tail = curr

â±ï¸ Complexity

Time: O(n) â†’ Traverses up to index.
Space: O(1) â†’ In-place modification.

ğŸ‘‰ Type: Doubly Linked List

1. Insert at Front
Key principle When inserting a node:
Link the new node to the existing nodes first. Then update the dummy node (head or tail) to point to the new node.

âœ¨ Flashcard
"Create a new node â†’ link between head and first real node."

head -> 5 -> 10 -> 20 -> tail       think with this example list for easier visualization

âš¡ Full Approach
Steps:

Create a new_node with the value.
Set new_node.prev = head.
Set new_node.next = head.next (the old first node).
Update the old first nodeâ€™s prev to point to new_node.
Update head.next to point to new_node.

â±ï¸ Complexity

Time: O(1) â†’ Direct pointer updates.
Space: O(1) â†’ No extra memory.

2. Insert at End

âœ¨ Flashcard
"Create a new node â†’ link between last node and tail."

head -> 5 -> 10 -> 20 -> tail

âš¡ Full Approach
Steps:

Create a new_node with the value.
Set new_node.next = tail.
Set new_node.prev = tail.prev (the old last node).
Update the old last nodeâ€™s next to point to new_node.
Update tail.prev to point to new_node.

â±ï¸ Complexity

Time: O(1)
Space: O(1)

3. Remove from Front
Key principle When removing a node:
Reconnect the previous and next nodes to each other first, then detach the target node.

âœ¨ Flashcard
"Skip the first node by connecting head to the second node."

head -> 5 -> 10 -> 20 -> tail


âš¡ Full Approach
Steps:

Check if the list is empty (head.next == tail).
If empty, print "List is empty" and return.
Update head.next to point to the second node.
Update the second nodeâ€™s prev to point to head.

â±ï¸ Complexity

Time: O(1)
Space: O(1)

4. Remove from End

âœ¨ Flashcard
"Skip the last node by connecting tail to the second-last node."

head -> 5 -> 10 -> 20 -> tail

âš¡ Full Approach
Steps:

Check if the list is empty (head.next == tail).
If empty, print "List is empty" and return.
Update tail.prev to point to the second-last node.
Update the second-last nodeâ€™s next to point to tail.

â±ï¸ Complexity

Time: O(1)
Space: O(1)

5. Print List

âœ¨ Flashcard
"Traverse from head to tail, printing each value."

âš¡ Full Approach
Steps:

Start at the node after head.
Keep moving forward using next.
Print each nodeâ€™s value until reaching tail.

â±ï¸ Complexity

Time: O(n) â†’ Must traverse all nodes.
Space: O(1) â†’ No extra memory.

ğŸ”¹ When to use deque vs list?
Use deque when you need fast appends/pops from both ends (O(1) time).
Use list when you need fast random access (indexing, slicing).

ğŸ‘‰ Type: Queue (Linked List with Dummy Node)

1. Enqueue (Insert at Tail)

âœ¨ Flashcard
"Create a new node â†’ attach to tail.next â†’ move tail pointer."

âš¡ Full Approach
Steps:
Create a new node with the given value.
Link the current tail.next to this new node.
Update tail to point to the new node.

â±ï¸ Complexity

Time: O(1) â†’ Constant-time insertion at the end.
Space: O(1) â†’ No extra memory besides the new node.

2. Dequeue (Remove from Head)

âœ¨ Flashcard
"Take value from head.next â†’ move head.next forward â†’ reset tail if empty."

âš¡ Full Approach

Steps:
If head.next is None, the queue is empty â†’ return None.
Store the value from head.next.val.
Update head.next to skip the removed node (head.next.next).
If the queue is now empty, reset tail = head.
Return the stored value.

â±ï¸ Complexity

Time: O(1) â†’ Constant-time removal from the front.
Space: O(1) â†’ No extra memory.

ğŸ‘‰ Type: Sorting Algorithm

1. Insertion Sort

âœ¨ Flashcard:
"Pick next element â†’ compare with sorted part â†’ shift bigger elements â†’ insert at correct position."

âš¡ Full Approach
Steps:
Start from the second element (i = 1).
Compare it with elements before it (j = i-1) in the sorted portion.

While the element at j is greater than current element, shift elements to the right:
tmp = arr[j+1]
arr[j+1] = arr[j]
arr[j] = tmp
Decrement j until you find the correct position.

Repeat for all elements (i = 1 â†’ len(arr)-1).

Return the sorted array.
â±ï¸ Complexity

Time:
Best: O(n) â†’ already sorted
Worst: O(nÂ²) â†’ reverse sorted
Space: O(1) â†’ sorts in place
Stable: Yes â†’ preserves relative order of equal elements

ğŸ‘‰ Type: In-Place Sorting (Heapsort)

âœ¨ Flashcard:
"Build max-heap â†’ swap root with end â†’ heapify reduced heap â†’ repeat."

âš¡ Full Approach
Steps:
Build a max-heap from the array.
Swap the root (max element) with the last element.
Reduce heap size by 1 and heapify the root.
Repeat until the heap size is 1.
Array becomes sorted in ascending order.

Heapify:
For a node i, compare with left and right children.
Swap with the largest child if necessary.
Continue heapifying down the subtree.

â±ï¸ Complexity

Time: O(n log n) â†’ building heap + extracting all elements
Space: O(1) extra â†’ in-place sorting
Stable: âŒ Heapsort is not stable

ğŸ‘‰ Type: In-Place Sorting (QuickSort)

âœ¨ Flashcard:
"Pick pivot â†’ partition array â†’ recursively sort left and right â†’ done."

âš¡ Full Approach
Steps:

Partition:
Pick the last element as pivot.
Rearrange elements so that all smaller elements are on the left, larger on the right.
Return the pivot index after partitioning.

Recursive Sort:
Recursively apply QuickSort to left of pivot and right of pivot.
Base case: if start â‰¥ end, return.

In-place:
No extra array needed â†’ minimal space
Recursion stack uses O(log n) on average.

â±ï¸ Complexity
Time: O(n log n)
Average: O(n log n)
Worst (already sorted pivot): O(nÂ²)

Space: O(log n) â†’ recursion stack
Worst-case stack: O(n) â†’ Occurs in worst case pivot choices (highly unbalanced splits).
Stable: âŒ QuickSort is not stable

ğŸ‘‰ Type: Divide & Conquer (MergeSort)

âœ… Key Idea
Divide: split array into smaller halves recursively.
Conquer: sort the tiny arrays (length 1 is already sorted).
Combine: merge sorted halves back together.

âœ¨ Flashcard:
"Divide array â†’ recursively sort halves â†’ merge sorted halves â†’ done."

âš¡ Full Approach
Steps:

Divide:
Split the array into two halves (midpoint).

Recursive Sort:
Recursively apply MergeSort on the left half.
Recursively apply MergeSort on the right half.

Merge:
Merge two sorted halves into one sorted array.
Use two pointers to compare elements from each half and build the sorted result.

Base Case:
If array has 0 or 1 element, return as already sorted.

In-place:
Standard MergeSort is not in-place because merging requires extra space O(n).
There are advanced in-place variants, but usually not used due to complexity.

â±ï¸ Complexity
Time:
    Best: O(n log n)
    Average: O(n log n)
    Worst: O(n log n)
Space: O(n) (extra arrays for merging)
Stable: âœ… MergeSort is stable

âœ… Notes:
Preferred for linked lists (easy to split & merge).
Consistent O(n log n) time regardless of input order.
Heavier on memory compared to QuickSort.

ğŸ‘‰ Type: Divide & Conquer (QuickSort)

âœ… Key Idea

Divide: pick a pivot and partition array into two groups: smaller than pivot & larger than pivot.

Conquer: recursively sort left and right groups.

Combine: pivot ends up in the right place automatically; nothing to merge.

âœ¨ Flashcard:
"Pick a pivot â†’ put smaller left, bigger right â†’ recursively sort sides â†’ done."

âš¡ Full Approach

Steps:
Choose Pivot:
Commonly the last element (arr[end]).

Partition:
Move all elements < pivot to the left.
Track index (partition_index) where pivot should finally sit.
Swap pivot into correct position.

Recursive Sort:
Recursively call QuickSort on the left side (start to partition_index - 1).
Recursively call QuickSort on the right side (partition_index + 1 to end).

Base Case:
If subarray length is 0 or 1, itâ€™s already sorted â†’ stop recursion.

In-place:

âœ… QuickSort sorts the array in place (O(1) extra space for swaps, aside from recursion stack).

âš ï¸ But recursion uses O(log n) space in the average case, O(n) in the worst case.

â±ï¸ Complexity

Time:
Best: O(n log n) (perfectly balanced partitions).
Average: O(n log n).
Worst: O(nÂ²) (bad pivots, e.g., already sorted array with naive pivot choice).
Space: O(log n) (recursion stack).
Stable: âŒ Not stable (relative order of equal elements may change).

âœ… Notes:
Very fast in practice due to good cache behavior & in-place sorting.
Widely used in standard libraries (with optimizations).
Picking a good pivot (e.g., random pivot or median-of-three) avoids worst-case.

ğŸ‘‰ Type: Divide & Conquer (3-way QuickSort / Dutch National Flag)

âœ… Key Idea

Divide: pick a random pivot and partition array into three groups:

Smaller than pivot
Equal to pivot
Larger than pivot

Conquer: recursively sort only the smaller and larger groups.

Combine: the equal-to-pivot block is already in the right place; nothing to merge.

âœ¨ Flashcard:
"Pick random pivot â†’ smaller left, equal middle, larger right â†’ recursively sort sides â†’ done."

âš¡ Full Approach

Steps:

Choose Pivot:
Pick a random element from the current subarray.
Swap it with the last element for convenience.

3-Way Partition:

Use three pointers:

lt â†’ boundary of elements < pivot
i â†’ current element
gt â†’ boundary of elements > pivot

Scan the array:

If nums[i] < pivot â†’ swap with lt, move both lt and i forward.
If nums[i] > pivot â†’ swap with gt, move gt backward (check new element at i).
If nums[i] == pivot â†’ just move i forward.

Recursive Sort:

Recursively sort left section (start to lt-1)
Recursively sort right section (gt+1 to end)

Base Case:

Stop recursion if subarray has 0 or 1 element.

In-place:
Sorting happens inside the original array.
Extra space: O(log n) for recursion stack.

â±ï¸ Complexity

Time:
Best: O(n log n) (balanced partitions)
Average: O(n log n)
Worst: O(nÂ²) (extremely rare with random pivot)

Space: O(log n) recursion stack

Stable: âŒ Not stable (equal elements may change order)

âœ… Notes:

Handles many duplicates efficiently (no TLE).
Random pivot ensures good average performance.
In-place sorting â†’ memory-efficient.

ğŸ‘‰ Type: Comparison-Based (Bubble Sort)

âœ… Key Idea
Repeatedly compare adjacent elements and swap them if they are in the wrong order.
With each pass, the largest element bubbles up to the end of the list.

âœ¨ Flashcard:
"Compare neighbors â†’ swap if out of order â†’ largest element moves to the end each pass â†’ repeat until sorted."

âš¡ Full Approach

Steps:
Outer Loop (i):
Runs n passes at most.
After each pass, the last element(s) are in correct position.

Inner Loop (j):
for j in range(0, n-i-1)
Compares each pair arr[j] and arr[j+1].
If arr[j] > arr[j+1], swap them.

Swapped Flag:
If no swaps occur in a full pass, the array is already sorted â†’ stop early.

Base Case:
If array length is 0 or 1, itâ€™s already sorted.

â±ï¸ Complexity
Time:
Best: O(n) (already sorted, only one pass).
Average: O(nÂ²).
Worst: O(nÂ²).

Space:
O(1) â†’ in-place sorting.

Stable: âœ… Yes (equal elements keep original order).

âœ… Notes:
Very simple, but inefficient for large arrays.
Good for teaching, not for production.
Useful when the array is almost sorted (best case O(n)).

ğŸ‘‰ Type: Counting-Based (Special Case of Counting Sort)

âœ… Key Idea
Count how many times each number appears (0, 1, or 2).
Then overwrite the original array by filling in 0s, then 1s, then 2s, according to their counts.

âœ¨ Flashcard:
"Count frequencies â†’ rewrite array with 0s, then 1s, then 2s â†’ sorted!"

âš¡ Full Approach

Steps:

Initialize Counts:
Create a counter list with three slots for 0, 1, and 2.

Count Elements:
Traverse the array and record how many times each number occurs.

Example:
Input â†’ [2, 0, 2, 1, 1, 0]
Counts â†’ [2, 2, 2] (2 zeros, 2 ones, 2 twos).

Refill Array In-Place:
Use the counts to rewrite the array: first all 0s, then all 1s, then all 2s.

Return Sorted Array:
Final result â†’ [0, 0, 1, 1, 2, 2].

â±ï¸ Complexity

Time: O(n) â†’ one pass to count, one pass to rebuild.

Space: O(1) â†’ only 3 extra counters.

Stable: âœ… Yes (relative order of equal elements doesnâ€™t change because we just group them).

âœ… Notes:

More efficient than comparison-based sorts for this restricted case.
Works only when the array contains 0, 1, and 2.
A generalized version is Counting Sort, which works for any integer range.